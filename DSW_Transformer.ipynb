{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuClass": "premium",
      "authorship_tag": "ABX9TyMc1v1BHJcfqV3t14PpOoum",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c92fde2f46fb4a019f6722eabb598a22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed625f4800b44b7c84179ab2be114deb",
              "IPY_MODEL_a85e096fa18044e6af36e5ccd6d61c08",
              "IPY_MODEL_3612856b0a8a422188e6608a66ee49db"
            ],
            "layout": "IPY_MODEL_4796b18cd02a4fd793f0836a605439a4"
          }
        },
        "ed625f4800b44b7c84179ab2be114deb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5d1817dd1d042bc812b4996b649d672",
            "placeholder": "​",
            "style": "IPY_MODEL_9c4a536942d54550b207981b3a542747",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "a85e096fa18044e6af36e5ccd6d61c08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d7608d8eeef41cfa487d5f91261154c",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76ae98d092234b57a263647cb9b99287",
            "value": 28
          }
        },
        "3612856b0a8a422188e6608a66ee49db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f32e4a2313f42298ad9f5eab911e06b",
            "placeholder": "​",
            "style": "IPY_MODEL_afa72f2982cd4f178beda28e6c6314ac",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.55kB/s]"
          }
        },
        "4796b18cd02a4fd793f0836a605439a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5d1817dd1d042bc812b4996b649d672": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c4a536942d54550b207981b3a542747": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d7608d8eeef41cfa487d5f91261154c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76ae98d092234b57a263647cb9b99287": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f32e4a2313f42298ad9f5eab911e06b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afa72f2982cd4f178beda28e6c6314ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "248a1eab00fa48ef9991cac217504d4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6700e3d859d7413a905601c9b1910656",
              "IPY_MODEL_9e730d73e2724742b6ee7bd3564f138b",
              "IPY_MODEL_6076390274cf4394b38de0ad7be1301f"
            ],
            "layout": "IPY_MODEL_34ac9459b5db4311b716e7c1d8645e9f"
          }
        },
        "6700e3d859d7413a905601c9b1910656": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3538e5adaea94c32a0212e70e7277a62",
            "placeholder": "​",
            "style": "IPY_MODEL_92ec36d1b19f4abda8b1444746052afc",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "9e730d73e2724742b6ee7bd3564f138b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f148c93efe0f441cb251daf8f865085f",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6f2496048b6c45cf902bf7310b8cd0bb",
            "value": 231508
          }
        },
        "6076390274cf4394b38de0ad7be1301f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d543c81cc91475da9440212482e715d",
            "placeholder": "​",
            "style": "IPY_MODEL_f9b20e328cf94e3483f976a50e98d7d0",
            "value": " 232k/232k [00:00&lt;00:00, 965kB/s]"
          }
        },
        "34ac9459b5db4311b716e7c1d8645e9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3538e5adaea94c32a0212e70e7277a62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92ec36d1b19f4abda8b1444746052afc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f148c93efe0f441cb251daf8f865085f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f2496048b6c45cf902bf7310b8cd0bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d543c81cc91475da9440212482e715d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9b20e328cf94e3483f976a50e98d7d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37e237e164974ed28e88d9a9c9731a5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0383c565f134398a74855b5d850c98e",
              "IPY_MODEL_3bd5ae20940440df84355a845c2c2952",
              "IPY_MODEL_c56e1fe31fbe414984c40f7e5909893f"
            ],
            "layout": "IPY_MODEL_f95633892cf74f12895819b4119888f1"
          }
        },
        "e0383c565f134398a74855b5d850c98e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a45835632ae74b14ab72a112b944d4d9",
            "placeholder": "​",
            "style": "IPY_MODEL_ed38949ed5d34b62872f0fe035b92866",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "3bd5ae20940440df84355a845c2c2952": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e907135b5344f2fbc228b9e5f9b775a",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8ec49da197c45ba8e484eb2a6fd8c81",
            "value": 466062
          }
        },
        "c56e1fe31fbe414984c40f7e5909893f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fb267349c8f4065bac8b50c237c65c7",
            "placeholder": "​",
            "style": "IPY_MODEL_ad1f3f7d77bd4be3a59af679c50c5a97",
            "value": " 466k/466k [00:00&lt;00:00, 683kB/s]"
          }
        },
        "f95633892cf74f12895819b4119888f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a45835632ae74b14ab72a112b944d4d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed38949ed5d34b62872f0fe035b92866": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e907135b5344f2fbc228b9e5f9b775a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8ec49da197c45ba8e484eb2a6fd8c81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8fb267349c8f4065bac8b50c237c65c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad1f3f7d77bd4be3a59af679c50c5a97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36af3a88f816450da4b163a7caa23f7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d22f0304bf2427eb2a8c0727f11abc5",
              "IPY_MODEL_ce9b06e1dec4462f9f0862d8aac23b65",
              "IPY_MODEL_36c1b6245c2444a0ab84306d52b535f8"
            ],
            "layout": "IPY_MODEL_18d4960bc4d04776b58ac1141c2fb5ff"
          }
        },
        "4d22f0304bf2427eb2a8c0727f11abc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82996a073cf0475e9a6db33cbe3c2b8a",
            "placeholder": "​",
            "style": "IPY_MODEL_769b2b5a808f48dca1729b299a92dd9a",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "ce9b06e1dec4462f9f0862d8aac23b65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f1a3ca01d774a36a9fecaf073bf9995",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12cb8f41495245c6943eb8a8ea2ad7a9",
            "value": 570
          }
        },
        "36c1b6245c2444a0ab84306d52b535f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f7148180d504a32a086bfa7a3379131",
            "placeholder": "​",
            "style": "IPY_MODEL_57f144628fe04ec19bed9f3b50fae062",
            "value": " 570/570 [00:00&lt;00:00, 30.3kB/s]"
          }
        },
        "18d4960bc4d04776b58ac1141c2fb5ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82996a073cf0475e9a6db33cbe3c2b8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "769b2b5a808f48dca1729b299a92dd9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f1a3ca01d774a36a9fecaf073bf9995": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12cb8f41495245c6943eb8a8ea2ad7a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f7148180d504a32a086bfa7a3379131": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57f144628fe04ec19bed9f3b50fae062": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a5c7ca5e0b8494195cead56fe57bc8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd7f472d788a4284b2952ff1dbe7078d",
              "IPY_MODEL_8b2f79864f4a4f3d86b5d827e168d076",
              "IPY_MODEL_2edce4ce2aba49eaadbb2f17536c1615"
            ],
            "layout": "IPY_MODEL_bbab2f51bd4349ff9e30bdb9d32d85aa"
          }
        },
        "cd7f472d788a4284b2952ff1dbe7078d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23b6a0db2dca48a6af0bc34496a52c7d",
            "placeholder": "​",
            "style": "IPY_MODEL_883c016c5b5a47bba95b0debebd47c79",
            "value": "Map: 100%"
          }
        },
        "8b2f79864f4a4f3d86b5d827e168d076": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a450889888d24306ac87684b06d39cc8",
            "max": 204045,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b90b5a4d99840e691d543dbcf11eb86",
            "value": 204045
          }
        },
        "2edce4ce2aba49eaadbb2f17536c1615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6418f32439f45f2b16ca5d77b1d1805",
            "placeholder": "​",
            "style": "IPY_MODEL_c3a2678a96b442e6ae4f04b85225984c",
            "value": " 204000/204045 [06:15&lt;00:00, 565.77 examples/s]"
          }
        },
        "bbab2f51bd4349ff9e30bdb9d32d85aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "23b6a0db2dca48a6af0bc34496a52c7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "883c016c5b5a47bba95b0debebd47c79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a450889888d24306ac87684b06d39cc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b90b5a4d99840e691d543dbcf11eb86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6418f32439f45f2b16ca5d77b1d1805": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3a2678a96b442e6ae4f04b85225984c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "752f35d6565f4921bf7faad5e5de09f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e67c4460e39a42de9a6a25c11b1a507e",
              "IPY_MODEL_010ffcd2ce9a410e920eed12f714a7c4",
              "IPY_MODEL_fce09968a5c54e5ca6f531ddd535fd4b"
            ],
            "layout": "IPY_MODEL_07b3a430fe6246309bda1291890d01e3"
          }
        },
        "e67c4460e39a42de9a6a25c11b1a507e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a5fbadd5b784b0fa91dbd241672c74c",
            "placeholder": "​",
            "style": "IPY_MODEL_caebab4f9e414fb4b51e941a134496a1",
            "value": "Map: 100%"
          }
        },
        "010ffcd2ce9a410e920eed12f714a7c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de1d1c59e7f6470caaf3a28a624d78d2",
            "max": 18949,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6db1dc28b4354dd4976eb6d6905814bf",
            "value": 18949
          }
        },
        "fce09968a5c54e5ca6f531ddd535fd4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e8032089113407880a93ae85fca1a99",
            "placeholder": "​",
            "style": "IPY_MODEL_a34a5ca3fbf14c5c82a346ccffa46bd0",
            "value": " 18912/18949 [00:50&lt;00:00, 387.67 examples/s]"
          }
        },
        "07b3a430fe6246309bda1291890d01e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "8a5fbadd5b784b0fa91dbd241672c74c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "caebab4f9e414fb4b51e941a134496a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de1d1c59e7f6470caaf3a28a624d78d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6db1dc28b4354dd4976eb6d6905814bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e8032089113407880a93ae85fca1a99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a34a5ca3fbf14c5c82a346ccffa46bd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/git-ekeh/custom_dsw_transformer/blob/main/DSW_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QMd3XumSSg9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "class WindowedAttention(Layer):\n",
        "    '''\n",
        "    Initialize the `WindowedAttention` layer with hyperparameters and required\n",
        "    dense layers\n",
        "    '''\n",
        "    def __init__(self, num_heads, d_model, window_size, dilation=1, global_attention_indices=None):\n",
        "        super(WindowedAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "        self.window_size = window_size\n",
        "        self.dilation = dilation\n",
        "        self.global_attention_indices = global_attention_indices\n",
        "\n",
        "        self.depth = d_model // num_heads\n",
        "        self.wq = tf.keras.layers.Dense(d_model) # regular densely-connected NN Layer\n",
        "        self.wk = tf.keras.layers.Dense(d_model) # regular densely-connected NN Layer\n",
        "        self.wv = tf.keras.layers.Dense(d_model) # regular densely-connected NN Layer\n",
        "        self.dense = tf.keras.layers.Dense(d_model) # regular densely-connected NN Layer\n",
        "        self.dropout = tf.keras.layers.Dropout\n",
        "        #self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "        #self.add = tf.keras.layers.Add()\n",
        "\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        '''\n",
        "        Define the `split_heads` function which reshapes and transposes the\n",
        "        input tensor to separate the attention heads\n",
        "        '''\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        x = tf.reshape(x, (batch_size, seq_len, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0,2,1,3])\n",
        "\n",
        "    def call(self, q, k, v, mask):\n",
        "        '''\n",
        "        Define the `call` function, which is executed when the layer is called.\n",
        "        This function computes the attention weights and output of the\n",
        "        windowed attention layer\n",
        "        '''\n",
        "\n",
        "        batch_size = tf.shape(q)[0]\n",
        "        seq_len = tf.shape(q)[1]\n",
        "\n",
        "        q = self.wq(q)\n",
        "        k = self.wk(k)\n",
        "        v = self.wv(v)\n",
        "\n",
        "\n",
        "        q = self.split_heads(q, batch_size)\n",
        "        k = self.split_heads(k, batch_size)\n",
        "        v = self.split_heads(v, batch_size)\n",
        "\n",
        "        #print(\"q shape after split_heads:\", q.shape)\n",
        "        #print(\"k shape after split_heads:\", k.shape)\n",
        "        #print(\"v shape after split_heads:\", v.shape)\n",
        "\n",
        "\n",
        "        # Create the mask using the create_window_mask function\n",
        "        mask = create_window_mask(seq_len, self.window_size, self.dilation, self.global_attention_indices)\n",
        "        mask = tf.cast(mask, dtype=tf.float32)\n",
        "        mask = tf.expand_dims(mask, axis=0) # Expand the dimensions\n",
        "        mask = tf.expand_dims(mask, axis=1) # Expand the dimensions\n",
        "        # Make sure the mask is compatible with the shape of the scaled_attention_logits\n",
        "        mask = tf.broadcast_to(mask, [batch_size, self.num_heads, seq_len, seq_len])  # Broadcast the mask to match the shape of scaled_attention_logits\n",
        "\n",
        "        scaled_attention_logits = tf.matmul(q, k, transpose_b=True) / tf.sqrt(tf.cast(self.depth, tf.float32))\n",
        "        mask = tf.stop_gradient(mask)\n",
        "        scaled_attention_logits += (mask * -1e9)\n",
        "        #print(\"scaled_attention_logits shape:\", scaled_attention_logits.shape)\n",
        "        #print(\"mask shape:\", mask.shape)\n",
        "\n",
        "        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
        "        #print(\"attention_weights shape:\", attention_weights.shape)\n",
        "        #attention_weights = self.dropout(attention_weights)\n",
        "\n",
        "\n",
        "\n",
        "        output = tf.matmul(attention_weights, v)\n",
        "        #print(\"output shape before dense layer:\", output.shape)\n",
        "        output = tf.transpose(output, perm=[0, 2, 1, 3])\n",
        "        seq_len = tf.shape(q)[2] # Get the sequence length from the q tensor\n",
        "\n",
        "        output = tf.reshape(output, (batch_size, seq_len, self.d_model))\n",
        "\n",
        "        output = self.dense(output)\n",
        "        #print(\"output shape after dense layer:\", output.shape)\n",
        "\n",
        "\n",
        "        return output\n",
        "\n",
        "def create_window_mask(seq_len, window_size, dilation=1, global_attention_indices=None):\n",
        "    '''\n",
        "    The `create_window_mask` function creates a boolean mask based on the input\n",
        "    sequence length, window size, dilation, and global attention indices. The purpose\n",
        "    of this mask is to specify which tokens should attend to each other within the\n",
        "    windowed and dilated attention mechanism\n",
        "    '''\n",
        "    mask = tf.eye(seq_len, dtype=tf.bool) # Create an identity matrix of shape (seq_len, seq_len) with a boolean data type. This sets the intitial mask, where each token attends to itself\n",
        "    half_window = window_size // 2 # Calculate half of the window size\n",
        "\n",
        "    def while_body(j, mask):\n",
        "        computed_value = seq_len - j * dilation\n",
        "        diag = tf.ones(computed_value, dtype=tf.bool)\n",
        "        mask = tf.linalg.set_diag(mask, diag, k=j*dilation)\n",
        "        mask = tf.linalg.set_diag(mask, diag, k=-j*dilation)\n",
        "        return j + 1, mask\n",
        "    def while_cond(j, _):\n",
        "        computed_value = seq_len - j * dilation\n",
        "        return computed_value > 0\n",
        "    _, mask = tf.while_loop(while_cond, while_body, (1, mask))\n",
        "\n",
        "    if global_attention_indices is not None:\n",
        "        '''\n",
        "        if global attention indices are provided, loop through each index and\n",
        "        set the corresponding diagonals in the mask tensor to ones. This ensures\n",
        "        that tokens with global attention attend to all tokens across the sequences\n",
        "        and vice versa\n",
        "        '''\n",
        "        for idx in global_attention_indices:\n",
        "            if idx == 0:\n",
        "                continue\n",
        "            diag_length = min(idx, seq_len - idx)\n",
        "            diag = tf.ones(diag_length, dtype=tf.bool)\n",
        "            mask = tf.linalg.set_diag(mask, diag, k=idx)\n",
        "            mask = tf.linalg.set_diag(mask, diag, k=-idx)\n",
        "    mask = tf.stop_gradient(mask)\n",
        "    return mask\n",
        "\n",
        "\n",
        "class BaseAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__()\n",
        "        self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
        "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "        self.add = tf.keras.layers.Add()\n",
        "\n",
        "'''\n",
        "The cross attention layer:\n",
        "\n",
        "---> At the literal center for the Transformer is the cross-attention layer. This layer connects the\n",
        "     encoder and decoder. This layer is the most straight-forward use of attention in the model\n",
        "\n",
        "---> To implement this you pass the target sequence x as the query and the context sequence as the\n",
        "     key/value when calling the mha layer\n",
        "'''\n",
        "\n",
        "class CrossAttention(BaseAttention):\n",
        "    def call(self, x, context):\n",
        "        attn_output, attn_scores = self.mha(\n",
        "            query=x,\n",
        "            key=context,\n",
        "            value=context,\n",
        "            return_attention_scores=True)\n",
        "\n",
        "        # Cache the attention scores for plotting later\n",
        "        self.last_attn_scores = attn_scores\n",
        "\n",
        "        x = self.add([x, attn_output])\n",
        "        x = self.layernorm(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "#mask = create_window_mask(seq_len=100, window_size=10, dilation=2, global_attention_indices=[0,50])\n",
        "#attention_layer = WindowedAttention(num_heads=8, d_model=512, window_size=10, dilation=2, global_attention_indices=[0,50])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, dff, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.seq = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(dff, activation='relu'),\n",
        "            tf.keras.layers.Dense(d_model),\n",
        "            tf.keras.layers.Dropout(dropout_rate)\n",
        "        ])\n",
        "\n",
        "        self.add = tf.keras.layers.Add()\n",
        "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.add([x, self.seq(x)])\n",
        "        x = self.layer_norm(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "-KFQ3XtUWlFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install spacy"
      ],
      "metadata": {
        "id": "5Bf8FRnHWyab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "import numpy as np\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "'''\n",
        "- Needs to take in the source documents and vectorize them\n",
        "- Then choose the top keywords in the document\n",
        "- Use those as guidance signals for training\n",
        "- for each source document, run it through the TextRank for keyword extraction\n",
        "'''\n",
        "\n",
        "class TextRank4Keyword():\n",
        "    '''Extract keywords from text'''\n",
        "\n",
        "    def __init__(self):\n",
        "        self.d = 0.85 # damping coefficient, usually is .85\n",
        "        self.min_diff = 1e-5 # converge threshold\n",
        "        self.steps = 10 # iteration steps\n",
        "        self.node_weight = None # save keywords and its weight\n",
        "\n",
        "    def set_stopwords(self, stopwords):\n",
        "        '''Set stop words'''\n",
        "        for word in STOP_WORDS.union(set(stopwords)):\n",
        "            lexeme = nlp.vocab[word]\n",
        "            lexeme.is_stop = True\n",
        "\n",
        "    def sentence_segment(self, doc, candidate_pos, lower):\n",
        "        '''Store those words only in candidate_pos'''\n",
        "        sentences = []\n",
        "        for sent in doc.sents:\n",
        "            selected_words = []\n",
        "            for token in sent:\n",
        "                # Store words only with candidate POS tag\n",
        "                if token.pos_ in candidate_pos and token.is_stop is False:\n",
        "                    if lower is True:\n",
        "                        selected_words.append(token.text.lower())\n",
        "                    else:\n",
        "                        selected_words.append(token.text)\n",
        "            sentences.append(selected_words)\n",
        "        return sentences\n",
        "\n",
        "    def get_vocab(self, sentences):\n",
        "        '''Get all tokens'''\n",
        "        vocab = OrderedDict()\n",
        "        i = 0\n",
        "        for sentence in sentences:\n",
        "            for word in sentence:\n",
        "                if word not in vocab:\n",
        "                    vocab[word] = i\n",
        "                    i += 1\n",
        "        return vocab\n",
        "\n",
        "    def get_token_pairs(self, window_size, sentences):\n",
        "        '''Build token_pairs from windows in sentences'''\n",
        "        token_pairs = list()\n",
        "        for sentence in sentences:\n",
        "            for i, word in enumerate(sentence):\n",
        "                for j in range(i+1, i+window_size):\n",
        "                    if j >= len(sentence):\n",
        "                        break\n",
        "                    pair = (word, sentence[j])\n",
        "                    if pair not in token_pairs:\n",
        "                        token_pairs.append(pair)\n",
        "        return token_pairs\n",
        "\n",
        "    def symmetrize(self, a):\n",
        "        return a + a.T - np.diag(a.diagonal())\n",
        "\n",
        "    def get_matrix(self, vocab, token_pairs):\n",
        "        '''Get normalized matrix'''\n",
        "        # Build matrix\n",
        "        vocab_size = len(vocab)\n",
        "        g = np.zeros((vocab_size, vocab_size), dtype='float')\n",
        "        for word1, word2 in token_pairs:\n",
        "            i, j = vocab[word1], vocab[word2]\n",
        "            g[i][j] = 1\n",
        "\n",
        "        # Get Symmetric matrix\n",
        "        g = self.symmetrize(g)\n",
        "\n",
        "        # Normalize matrix by column\n",
        "        norm = np.sum(g, axis=0)\n",
        "        g_norm = np.divide(g, norm, where=norm!=0) # thisd is to ignore the 0 element in norm\n",
        "\n",
        "        return g_norm\n",
        "\n",
        "    def get_keywords(self, number=10):\n",
        "        '''Print top number keywords'''\n",
        "        node_weight = OrderedDict(sorted(self.node_weight.items(), key=lambda t: t[1], reverse=True))\n",
        "        keyword_store = []\n",
        "        for i, (key,value) in enumerate(node_weight.items()):\n",
        "            keyword_store.append(str(key))\n",
        "            #print(key + ' - ' + str(value))\n",
        "            #print(key)\n",
        "\n",
        "            if i > number:\n",
        "                break\n",
        "        return keyword_store\n",
        "\n",
        "\n",
        "\n",
        "    def analyze(self, text,\n",
        "                candidate_pos=['NOUN','PROPN'],\n",
        "                window_size=4, lower=False, stopwords=list()):\n",
        "        '''Main function to analyze text'''\n",
        "\n",
        "        # Set stop words\n",
        "        self.set_stopwords(stopwords)\n",
        "\n",
        "        # Parse text by spaCy\n",
        "        doc = nlp(text)\n",
        "\n",
        "        # Filter sentences\n",
        "        sentences = self.sentence_segment(doc, candidate_pos, lower) # list of list of words\n",
        "\n",
        "        # Build vocabulary\n",
        "        vocab = self.get_vocab(sentences)\n",
        "\n",
        "        # Get token_pairs from windows\n",
        "        token_pairs = self.get_token_pairs(window_size, sentences)\n",
        "\n",
        "        # Get normalized matrix\n",
        "        g = self.get_matrix(vocab, token_pairs)\n",
        "\n",
        "        # Initialization for weight(pagerank value)\n",
        "        pr = np.array([1] * len(vocab))\n",
        "\n",
        "        # Iteration\n",
        "        previous_pr = 0\n",
        "        for epoch in range(self.steps):\n",
        "            pr = (1-self.d) + self.d * np.dot(g, pr)\n",
        "            if abs(previous_pr - sum(pr)) < self.min_diff:\n",
        "                break\n",
        "            else:\n",
        "                previous_pr = sum(pr)\n",
        "\n",
        "        # Get weight for each node\n",
        "        node_weight = dict()\n",
        "        for word, index in vocab.items():\n",
        "            node_weight[word] = pr[index]\n",
        "\n",
        "        self.node_weight = node_weight\n"
      ],
      "metadata": {
        "id": "blWz_bBXWm9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(length, depth):\n",
        "    depth = depth/2\n",
        "\n",
        "    positions = np.arange(length)[:, np.newaxis]  # (seq, 1)\n",
        "    depths = np.arange(depth)[np.newaxis, :]/depth # (1, depth)\n",
        "\n",
        "    angle_rates = 1 / (10000**depths) #(1, depth)\n",
        "    angle_rads = positions * angle_rates #(pos, depth)\n",
        "\n",
        "    pos_encoding = np.concatenate(\n",
        "        [np.sin(angle_rads), np.cos(angle_rads)],\n",
        "        axis=-1)\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "class PositionalEmbedding(tf.keras.layers.Layer):\n",
        "    def __init__(self, vocab_size, d_model):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)\n",
        "        self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
        "\n",
        "    def compute_mask(self, *args, **kwargs):\n",
        "        return self.embedding.compute_mask(*args, **kwargs)\n",
        "\n",
        "    def call(self, x):\n",
        "        length = tf.shape(x)[1]\n",
        "        x = self.embedding(x)\n",
        "        # This factor sets the relative scale of the emebdding and positional_encoding\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "o4UhmB4vXBGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, *, d_model, num_heads, dff, window_size, dilation=1, global_attention_indices=None, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.windowed_attention = WindowedAttention(\n",
        "            num_heads=num_heads,\n",
        "            d_model=d_model,\n",
        "            window_size=window_size,\n",
        "            dilation=dilation)\n",
        "\n",
        "        self.ffn = FeedForward(d_model, dff)\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        #print('x shape before the windowed_attention layer', x.shape)\n",
        "        x = self.windowed_attention(x,k=x,v=x, mask=mask) #removed mask\n",
        "        #print('x shape before the feedforward layer', x.shape)\n",
        "        x = self.ffn(x)\n",
        "        return x\n",
        "\n",
        "class Encoder(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, *, num_layers, d_model, num_heads, dff, window_size, dilation=1, global_attention_indices=None, vocab_size, dropout_rate=0.1):\n",
        "\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size, d_model=d_model)\n",
        "        self.enc_layers = [\n",
        "            EncoderLayer(d_model=d_model,\n",
        "                         num_heads=num_heads,\n",
        "                         dff=dff,\n",
        "                         window_size=window_size,\n",
        "                         dilation=dilation,\n",
        "                         global_attention_indices=global_attention_indices,\n",
        "                         dropout_rate=dropout_rate)\n",
        "                         for _ in range(num_layers)]\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        # `x` is token-IDs shape: (batch, seq_len)\n",
        "        x = self.pos_embedding(x) # Shape `(batch_size, seq_len, d_model)`\n",
        "\n",
        "        # Add dropout\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, mask=mask) # Pass the training flag also removed mask=mask\n",
        "\n",
        "        return x #Shape `(batch_size, seq_len, d_model)`\n"
      ],
      "metadata": {
        "id": "tMfNI7MHXSzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, *, d_model, num_heads, dff, window_size, dilation, dropout_rate=0.1):\n",
        "\n",
        "                super(DecoderLayer, self).__init__()\n",
        "\n",
        "                self.windowed_self_attention = WindowedAttention(\n",
        "                    num_heads=num_heads,\n",
        "                    d_model=d_model,\n",
        "                    window_size=window_size,\n",
        "                    dilation=dilation)\n",
        "\n",
        "                self.cross_attention0 = CrossAttention(\n",
        "                    num_heads=num_heads,\n",
        "                    key_dim=d_model,\n",
        "                    dropout=dropout_rate)\n",
        "\n",
        "                self.cross_attention1 = CrossAttention(\n",
        "                    num_heads=num_heads,\n",
        "                    key_dim=d_model,\n",
        "                    dropout=dropout_rate)\n",
        "\n",
        "\n",
        "                self.ffn = FeedForward(d_model, dff)\n",
        "\n",
        "    def call(self, x, context0, context1,mask=None, global_attention_indices=None): #global_attention_indices=None\n",
        "        # gotta build two cross attention mechanisms, one for guidance and one for source doc\n",
        "\n",
        "        x = self.windowed_self_attention(x, x, x, mask) # output embedding\n",
        "        guidance = self.cross_attention0(x=x, context=context0) #guidance multiplied by the output embedding\n",
        "\n",
        "        source = self.cross_attention1(x=guidance, context=context1) #guidance multiplied by the contents of the source document\n",
        "\n",
        "        final = self.ffn(source)  # Shape `(batch_size, seq_len, d_model)`.\n",
        "        #print(\"final shape:\", final.shape)\n",
        "        return final # instead of x\n",
        "\n",
        "\n",
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size, window_size, dilation, global_attention_indices=None, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size, d_model=d_model)\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "        self.dec_layers = [\n",
        "                    DecoderLayer(d_model=d_model, num_heads=num_heads, dff=dff, window_size=window_size, dilation=dilation,dropout_rate=dropout_rate)\n",
        "                    for _ in range(num_layers)]\n",
        "\n",
        "    def call(self, x, context0, context1, mask=None, global_attention_indices=None):\n",
        "        # `x` is token-IDs shape (batch, target_seq_len)\n",
        "        x = self.pos_embedding(x) # (batch_size, target_seq_len, d_model)\n",
        "        #print(\"x shape after pos_embedding:\", x.shape)\n",
        "\n",
        "\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.dec_layers[i](x, context0, context1, mask=mask, global_attention_indices=global_attention_indices)\n",
        "\n",
        "\n",
        "\n",
        "        # The shape of x is (batch_size, target_seq_len, d_model)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "oYo9Z8SPXbGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self, *, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, window_size, dilation, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.encoder0 = Encoder(num_layers=num_layers, d_model=d_model, num_heads=num_heads, dff=dff, vocab_size=input_vocab_size, window_size=window_size,dropout_rate=dropout_rate)\n",
        "        self.encoder1 = Encoder(num_layers=num_layers, d_model=d_model, num_heads=num_heads, dff=dff, vocab_size=input_vocab_size, window_size=window_size,dropout_rate=dropout_rate)\n",
        "\n",
        "        self.decoder = Decoder(num_layers=num_layers, d_model=d_model, num_heads=num_heads, dff=dff, vocab_size=target_vocab_size, window_size=window_size, dilation=dilation, dropout_rate=dropout_rate)\n",
        "\n",
        "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "    def call(self, inputs):\n",
        "\n",
        "        document = inputs['input_ids']\n",
        "        guidance = inputs['guidance_inputs']\n",
        "        x = inputs['decoder_input_ids']\n",
        "\n",
        "\n",
        "        # Process the document and guidance features in parallel through the two encoders\n",
        "        context0 = self.encoder0(document)\n",
        "        context1 = self.encoder1(guidance)\n",
        "\n",
        "\n",
        "        x = self.decoder(x, context0, context1, global_attention_indices=None) # (batch_size, target_len, d_model)\n",
        "\n",
        "        # Final linear layer output.\n",
        "        logits = self.final_layer(x) # (batch_size, target_len, target_vocab_size)\n",
        "\n",
        "        try:\n",
        "            # Drop the keras mask, so it does not scale the losses/metrics\n",
        "            # b/250038731\n",
        "            del logits._keras_mask\n",
        "        except AttributeError:\n",
        "            pass\n",
        "\n",
        "        # Return the final output and the attention weights\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "ht-M-NcfXjMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "SaHjKmgOnQgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install datasets\n",
        "!pip3 install transformers\n",
        "!pip3 install rouge-score"
      ],
      "metadata": {
        "id": "53BEZg1qbHWT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acc09644-48f6-4621-9a72-16d20ff4fb8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.11.0-py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.27.1)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill<0.3.7,>=0.3.0\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.0-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.2/224.2 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.5.3)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.4.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (4.65.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.3/269.3 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.11.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.11.0 dill-0.3.6 frozenlist-1.3.3 huggingface-hub-0.14.0 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.9.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.14.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "Successfully installed tokenizers-0.13.3 transformers-4.28.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from rouge-score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from rouge-score) (1.22.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from rouge-score) (1.16.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk->rouge-score) (2022.10.31)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->rouge-score) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->rouge-score) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk->rouge-score) (4.65.0)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24954 sha256=085500a31cec53c5c2e7f1cdff70ed26597764195801b2812ec4fd70c64d97fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/3d/39/09558097d3119ca0a4d462df68f22c6f3c1b345ac63a09b86e\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import tensorflow as tf\n",
        "import datasets\n",
        "import transformers\n",
        "from transformers import DataCollatorWithPadding\n",
        "from transformers import BertTokenizerFast, AutoTokenizer\n",
        "from transformers import DataCollatorWithPadding\n",
        "from datasets import load_dataset, Dataset\n",
        "import pandas as pd\n",
        "import collections\n",
        "import itertools\n",
        "import os\n",
        "\n",
        "# Open the file in rad-binary mode\n",
        "with open('train_dict.pkl', 'rb') as f:\n",
        "    # Load the pickled object from the file\n",
        "    unpickled_obj_train = pickle.load(f)\n",
        "\n",
        "with open('val_dict.pkl','rb') as f:\n",
        "    # Load the pickled validation set from the pickled file\n",
        "    unpickled_obj_val = pickle.load(f)\n",
        "\n",
        "'''\n",
        "My pickling job wasn't perfect but WE MOVE\n",
        "All 204045 examples were preprocessed into\n",
        "one file train_dict.pkl\n",
        "\n",
        "Ideal\n",
        "-----\n",
        "To accomodate I will split the examples\n",
        "into train: 70, val: 20, test: 10 split\n",
        "\n",
        "The data type is a dictionary\n",
        "\n",
        "keys are strings of integers\n",
        "\n",
        "Current\n",
        "-------\n",
        "Going to train using train_dict\n",
        "for both test and val\n",
        "'''\n",
        "\n",
        "# Convert dictionary to dataframe and transpose them to get the appropriate features of the dataframe\n",
        "df_train = pd.DataFrame.from_dict(unpickled_obj_train)\n",
        "\n",
        "df_val = pd.DataFrame.from_dict(unpickled_obj_val)\n",
        "# Transpose the dataframe\n",
        "transpose_df_train = df_train.T\n",
        "transpose_df_val = df_val.T\n",
        "# Convert the dataframe rows to lists to avoid error: TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]\n",
        "transpose_df_train['id'] = transpose_df_train['id'].values.tolist()\n",
        "transpose_df_val['title'] = transpose_df_val['title'].values.tolist()\n",
        "# Convert Dataframes to Datasets\n",
        "dataset_train = Dataset.from_pandas(transpose_df_train)\n",
        "dataset_train = dataset_train.remove_columns(\"__index_level_0__\")\n",
        "dataset_train = dataset_train.remove_columns(\"id\")\n",
        "\n",
        "dataset_val = Dataset.from_pandas(transpose_df_val)\n",
        "dataset_val = dataset_val.remove_columns(\"__index_level_0__\")\n",
        "dataset_val = dataset_val.remove_columns(\"title\")\n",
        "\n",
        "#Tokenization\n",
        "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
        "tokenizer.bos_token = tokenizer.cls_token\n",
        "tokenizer.eos_token = tokenizer.sep_token\n",
        "\n",
        "\n",
        "batch_size = 32 # this is for full training\n",
        "encoder_max_length = 512\n",
        "decoder_max_length = 512\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")\n",
        "\n",
        "def process_data_to_model_inputs(batch):\n",
        "    # tokenize the inputs and labels\n",
        "    inputs = tokenizer(batch[\"document\"],  padding=\"max_length\", truncation=True, max_length=encoder_max_length)\n",
        "    outputs = tokenizer(batch[\"summary\"], padding=\"max_length\", truncation=True, max_length=decoder_max_length)\n",
        "\n",
        "\n",
        "    #Concatenate guifance strings using the [SEP] token\n",
        "    guidance_text = [\"[SEP]\".join(guidance) for guidance in batch[\"guidance\"]]\n",
        "    guidance = tokenizer(guidance_text, padding=\"max_length\", truncation=True, max_length=encoder_max_length)\n",
        "\n",
        "\n",
        "    batch[\"input_ids\"] = inputs.input_ids\n",
        "    batch[\"attention_mask\"] = inputs.attention_mask\n",
        "    batch[\"guidance_inputs\"] = guidance.input_ids\n",
        "    batch[\"guidance_attention_mask\"] = guidance.attention_mask\n",
        "    batch[\"decoder_input_ids\"] = outputs.input_ids\n",
        "    batch[\"decoder_attention_mask\"] = outputs.attention_mask\n",
        "    batch[\"labels\"] = outputs.input_ids.copy()\n",
        "\n",
        "    # because BERT automatically shifts the labels, the labels correspond exctly to `decoder_input_ids`\n",
        "    # We have to make sure that he PAD token is ignored\n",
        "    #batch[\"labels\"] = [[-100 if token == tokenizer.pad_token_id else token for token in labels] for labels in batch[\"labels\"]]\n",
        "    batch[\"labels\"] = [[tokenizer.pad_token_id if token == tokenizer.pad_token_id else token for token in labels] for labels in batch[\"labels\"]]\n",
        "\n",
        "\n",
        "    return batch\n",
        "\n",
        "dataset_train = dataset_train.map(process_data_to_model_inputs,\n",
        "                                  batched=True,\n",
        "                                  batch_size = batch_size)\n",
        "\n",
        "def process_data_to_model_inputs_billsum(batch):\n",
        "    # tokenize the inputs and labels\n",
        "    inputs = tokenizer(batch[\"text\"],  padding=\"max_length\", truncation=True, max_length=encoder_max_length)\n",
        "    outputs = tokenizer(batch[\"summary\"], padding=\"max_length\", truncation=True, max_length=decoder_max_length)\n",
        "\n",
        "\n",
        "    #Concatenate guifance strings using the [SEP] token\n",
        "    guidance_text = [\"[SEP]\".join(guidance) for guidance in batch[\"guidance\"]]\n",
        "    guidance = tokenizer(guidance_text, padding=\"max_length\", truncation=True, max_length=encoder_max_length)\n",
        "\n",
        "\n",
        "    batch[\"input_ids\"] = inputs.input_ids\n",
        "    batch[\"attention_mask\"] = inputs.attention_mask\n",
        "    batch[\"guidance_inputs\"] = guidance.input_ids\n",
        "    batch[\"guidance_attention_mask\"] = guidance.attention_mask\n",
        "    batch[\"decoder_input_ids\"] = outputs.input_ids\n",
        "    batch[\"decoder_attention_mask\"] = outputs.attention_mask\n",
        "    batch[\"labels\"] = outputs.input_ids.copy()\n",
        "\n",
        "    # because BERT automatically shifts the labels, the labels correspond exctly to `decoder_input_ids`\n",
        "    # We have to make sure that he PAD token is ignored\n",
        "    #batch[\"labels\"] = [[-100 if token == tokenizer.pad_token_id else token for token in labels] for labels in batch[\"labels\"]]\n",
        "    batch[\"labels\"] = [[tokenizer.pad_token_id if token == tokenizer.pad_token_id else token for token in labels] for labels in batch[\"labels\"]]\n",
        "\n",
        "\n",
        "    return batch\n",
        "\n",
        "\n",
        "dataset_val = dataset_val.map(process_data_to_model_inputs_billsum,\n",
        "                                  batched=True,\n",
        "                                  batch_size = batch_size)\n",
        "\n",
        "# Converting the recently tokenized data into a tensorflow dataset\n",
        "dataset_train = dataset_train.to_tf_dataset(\n",
        "    columns=[\"input_ids\",\"attention_mask\",\"guidance_inputs\",\"guidance_attention_mask\",\"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
        "    label_cols=[\"labels\"],\n",
        "    batch_size = 2,\n",
        "    collate_fn=data_collator,\n",
        "    shuffle=True\n",
        ")\n",
        "'''\n",
        "# Saving this tensorflow datasets\n",
        "saved_dataset_train_dir = 'saved_train_tensors'\n",
        "if not os.path.exists(saved_dataset_train_dir):\n",
        "    os.makedirs(saved_dataset_train_dir)\n",
        "tf.data.experimental.save(\n",
        "                            dataset_train,\n",
        "                            saved_dataset_train_dir,\n",
        "                            compression='GZIP'\n",
        ")\n",
        "\n",
        "'''\n",
        "\n",
        "dataset_val = dataset_val.to_tf_dataset(\n",
        "    columns=[\"input_ids\",\"attention_mask\",\"guidance_inputs\",\"guidance_attention_mask\",\"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
        "    label_cols=[\"labels\"],\n",
        "    batch_size = 2,\n",
        "    collate_fn=data_collator,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183,
          "referenced_widgets": [
            "c92fde2f46fb4a019f6722eabb598a22",
            "ed625f4800b44b7c84179ab2be114deb",
            "a85e096fa18044e6af36e5ccd6d61c08",
            "3612856b0a8a422188e6608a66ee49db",
            "4796b18cd02a4fd793f0836a605439a4",
            "b5d1817dd1d042bc812b4996b649d672",
            "9c4a536942d54550b207981b3a542747",
            "3d7608d8eeef41cfa487d5f91261154c",
            "76ae98d092234b57a263647cb9b99287",
            "1f32e4a2313f42298ad9f5eab911e06b",
            "afa72f2982cd4f178beda28e6c6314ac",
            "248a1eab00fa48ef9991cac217504d4f",
            "6700e3d859d7413a905601c9b1910656",
            "9e730d73e2724742b6ee7bd3564f138b",
            "6076390274cf4394b38de0ad7be1301f",
            "34ac9459b5db4311b716e7c1d8645e9f",
            "3538e5adaea94c32a0212e70e7277a62",
            "92ec36d1b19f4abda8b1444746052afc",
            "f148c93efe0f441cb251daf8f865085f",
            "6f2496048b6c45cf902bf7310b8cd0bb",
            "8d543c81cc91475da9440212482e715d",
            "f9b20e328cf94e3483f976a50e98d7d0",
            "37e237e164974ed28e88d9a9c9731a5e",
            "e0383c565f134398a74855b5d850c98e",
            "3bd5ae20940440df84355a845c2c2952",
            "c56e1fe31fbe414984c40f7e5909893f",
            "f95633892cf74f12895819b4119888f1",
            "a45835632ae74b14ab72a112b944d4d9",
            "ed38949ed5d34b62872f0fe035b92866",
            "6e907135b5344f2fbc228b9e5f9b775a",
            "d8ec49da197c45ba8e484eb2a6fd8c81",
            "8fb267349c8f4065bac8b50c237c65c7",
            "ad1f3f7d77bd4be3a59af679c50c5a97",
            "36af3a88f816450da4b163a7caa23f7a",
            "4d22f0304bf2427eb2a8c0727f11abc5",
            "ce9b06e1dec4462f9f0862d8aac23b65",
            "36c1b6245c2444a0ab84306d52b535f8",
            "18d4960bc4d04776b58ac1141c2fb5ff",
            "82996a073cf0475e9a6db33cbe3c2b8a",
            "769b2b5a808f48dca1729b299a92dd9a",
            "1f1a3ca01d774a36a9fecaf073bf9995",
            "12cb8f41495245c6943eb8a8ea2ad7a9",
            "7f7148180d504a32a086bfa7a3379131",
            "57f144628fe04ec19bed9f3b50fae062",
            "2a5c7ca5e0b8494195cead56fe57bc8f",
            "cd7f472d788a4284b2952ff1dbe7078d",
            "8b2f79864f4a4f3d86b5d827e168d076",
            "2edce4ce2aba49eaadbb2f17536c1615",
            "bbab2f51bd4349ff9e30bdb9d32d85aa",
            "23b6a0db2dca48a6af0bc34496a52c7d",
            "883c016c5b5a47bba95b0debebd47c79",
            "a450889888d24306ac87684b06d39cc8",
            "2b90b5a4d99840e691d543dbcf11eb86",
            "a6418f32439f45f2b16ca5d77b1d1805",
            "c3a2678a96b442e6ae4f04b85225984c",
            "752f35d6565f4921bf7faad5e5de09f4",
            "e67c4460e39a42de9a6a25c11b1a507e",
            "010ffcd2ce9a410e920eed12f714a7c4",
            "fce09968a5c54e5ca6f531ddd535fd4b",
            "07b3a430fe6246309bda1291890d01e3",
            "8a5fbadd5b784b0fa91dbd241672c74c",
            "caebab4f9e414fb4b51e941a134496a1",
            "de1d1c59e7f6470caaf3a28a624d78d2",
            "6db1dc28b4354dd4976eb6d6905814bf",
            "1e8032089113407880a93ae85fca1a99",
            "a34a5ca3fbf14c5c82a346ccffa46bd0"
          ]
        },
        "id": "1R5U3D0pYniB",
        "outputId": "4e19f3cc-67c0-417f-c394-4b7ee21157d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c92fde2f46fb4a019f6722eabb598a22"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "248a1eab00fa48ef9991cac217504d4f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37e237e164974ed28e88d9a9c9731a5e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36af3a88f816450da4b163a7caa23f7a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/204045 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a5c7ca5e0b8494195cead56fe57bc8f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/18949 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "752f35d6565f4921bf7faad5e5de09f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge_score import rouge_scorer\n",
        "\n",
        "'''\n",
        "# Saving this tensorflow datasets\n",
        "\n",
        "saved_dataset_validation_dir = 'saved_validation_tensors'\n",
        "if not os.path.exists(saved_dataset_validation_dir):\n",
        "    os.makedirs(saved_dataset_validation_dir)\n",
        "tf.data.experimental.save(\n",
        "                            dataset_val,\n",
        "                            saved_dataset_validation_dir,\n",
        "                            compression='GZIP'\n",
        ")\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "# Define Hyperparameters\n",
        "num_layers = 4\n",
        "d_model = 128\n",
        "num_heads = 8\n",
        "dff = 512\n",
        "input_vocab_size = tokenizer.vocab_size\n",
        "target_vocab_size = tokenizer.vocab_size\n",
        "window_size = 130 # changed from 128\n",
        "dilation = 1\n",
        "dropout_rate = 0.1\n",
        "epochs = 10\n",
        "'''\n",
        "# Creating Rouge Score\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "# Define a custom function that computes the ROUGE score between y_true and y_pred\n",
        "def compute_rouge(y_true, y_pred):\n",
        "    # Convert the y_true and y_pred tensors to Python lists of strings\n",
        "    true_texts = tokenizer.batch_decode(y_true.np(), skip_special_tokens=True)\n",
        "    pred_texts = tokenizer.batch_decode(y_pred.np(), skip_special_tokens=True)\n",
        "\n",
        "    # Compute the ROUGE scores using the RougeScorer object\n",
        "    rouge_scores = scorer.score(true_texts, pred_texts)\n",
        "\n",
        "    # Return a dictionary of ROUGE scores\n",
        "    return {'rouge1': rouge_scores['rouge1'].fmeasure,\n",
        "            'rouge2': rouge_scores['rouge2'].fmeasure,\n",
        "            'rougeL': rouge_scores['rougeL'].fmeasure}\n",
        "'''\n",
        "# Define the metrics to use during training and validation\n",
        "metrics = ['accuracy']\n",
        "\n",
        "# Constructing the model\n",
        "\n",
        "model = Transformer(num_layers=num_layers, d_model=d_model, num_heads=num_heads, dff=dff,\n",
        "                    input_vocab_size=input_vocab_size, target_vocab_size = target_vocab_size,\n",
        "                    window_size = window_size, dilation=dilation,dropout_rate=dropout_rate)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "loss_function = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=metrics) # can also use any keras loss function\n",
        "\n",
        "history = model.fit(dataset_train, epochs=epochs, validation_data=dataset_val)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "dw-era3I0z3F",
        "outputId": "fd5798e5-a903-4896-b5a6-f1592acbd881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            " 33459/102023 [========>.....................] - ETA: 5:02:20 - loss: 0.6036 - accuracy: 0.9452"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-962cffa24b83>\u001b[0m in \u001b[0;36m<cell line: 59>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# can also use any keras loss function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_dict = history.history\n",
        "'''\n",
        "This should provide a dictionary with keys like:\n",
        " - 'loss'\n",
        " - 'accuracy'\n",
        " - 'val_loss'\n",
        " - 'val_accuracy'\n",
        "'''\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_training_history(history_dict):\n",
        "    loss = history_dict['loss']\n",
        "    val_loss = history_dict['val_loss']\n",
        "    accuracy = history_dict['accuracy']\n",
        "    val_accuracy = history_dict['val_accuracy']\n",
        "    epochs = range(1, len(loss) + 1)\n",
        "\n",
        "    # Plot training and validation loss\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "    plt.plot(epochs, val_loss, 'b', label='Validation accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "plot_training_history(history_dict)"
      ],
      "metadata": {
        "id": "TK9kG6WqaRH2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}